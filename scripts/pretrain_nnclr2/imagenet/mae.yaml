defaults:
  - _self_
  - augmentations: reconstruction.yaml
  - augmentations: reconstruction.yaml
  - nn_augmentations: no_transform.yaml
  - emb_model: resnet50.yaml
  - wandb: private.yaml
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

# disable hydra outputs
hydra:
  output_subdir: null
  run:
    dir: .

name: "mae-imagenet"
method: "mae"
nnclr2: True
nn_key: "feats"
log_path: "/network/scratch/f/feiziaar/ht-image-ssl/logs/"
backbone:
  name: "vit_base"
method_kwargs:
  decoder_embed_dim: 512
  decoder_depth: 8
  decoder_num_heads: 16
  mask_ratio: 0.75
  norm_pix_loss: True
momentum:
  base_tau: 0.9995
  final_tau: 1.0
data:
  dataset: imagenet
  train_path: "/network/datasets/imagenet.var/imagenet_torchvision/train"
  val_path: "/network/datasets/imagenet.var/imagenet_torchvision/val"
  format: "image_folder"
  num_workers: 10
  num_nns_choice: 1
  num_nns: 1
  filter_sim_matrix: False
  reload_freq: 0
  emb_path: ''
optimizer:
  name: "adamw"
  batch_size: 512
  lr: 2.0e-4
  classifier_lr: 2.0e-4
  weight_decay: 0.05
  kwargs:
    betas: [0.9, 0.95]
scheduler:
  name: "warmup_cosine"
checkpoint_config:
  enabled: True
  dir: "/network/scratch/f/feiziaar/ht-image-ssl/trained_models"
  frequency: 1
auto_resume:
  enabled: True

# overwrite PL stuff
max_epochs: 400
devices: [0, 1]
sync_batchnorm: True
accelerator: "gpu"
strategy: "ddp"
precision: 16
test: True